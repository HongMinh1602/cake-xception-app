import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from PIL import Image
from fpdf import FPDF
import tempfile
import io
import os
import gdown
import streamlit.components.v1 as components
import pandas as pd
from math import radians, sin, cos, sqrt, atan2

def download_model_if_needed():
    model_path = "Xception_banh_model.keras"
    if not os.path.exists(model_path):
        file_id = "1SW5eLCyuDK4n1hOTCedBbKrtAjpEuNaC"
        url = f"https://drive.google.com/uc?id={file_id}"
        gdown.download(url, model_path, quiet=False)

# T·∫£i model n·∫øu c·∫ßn
download_model_if_needed()

def haversine(lat1, lon1, lat2, lon2):
    R = 6371  # B√°n k√≠nh Tr√°i ƒê·∫•t (km)
    dlat = radians(lat2 - lat1)
    dlon = radians(lon2 - lon1)
    a = sin(dlat/2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    return R * c  # k·∫øt qu·∫£ tr·∫£ v·ªÅ t√≠nh b·∫±ng km

def create_pdf(image_path, pred_class, confidence, preds, class_names, bar_fig):
    pdf = FPDF()
    pdf.set_left_margin(15)
    pdf.set_right_margin(20)
    pdf.set_auto_page_break(auto=True, margin=20)
    pdf.add_page()

    font_folder = os.getcwd()
    pdf.add_font("DejaVu", "", os.path.join(font_folder, "DejaVuSans.ttf"), uni=True)
    pdf.add_font("DejaVu", "B", os.path.join(font_folder, "DejaVuSans-Bold.ttf"), uni=True)

    pdf.set_font("DejaVu", 'B', 16)
    pdf.cell(0, 10, txt="B√ÅO C√ÅO PH√ÇN LO·∫†I B√ÅNH", ln=True, align="C")
    pdf.ln(10)

    tmp_dir = tempfile.mkdtemp()
    input_img_path = os.path.join(tmp_dir, "input.jpg")
    bar_path = os.path.join(tmp_dir, "bar.png")

    image_path.save(input_img_path)
    bar_fig.savefig(bar_path, bbox_inches='tight')

    pdf.set_font("DejaVu", 'B', 12)
    pdf.cell(90, 10, "·∫¢nh ƒë·∫ßu v√†o", ln=0)
    pdf.cell(0, 10, "K·∫øt qu·∫£ d·ª± ƒëo√°n", ln=1)

    pdf.image(input_img_path, x=15, y=pdf.get_y(), w=60)

    y_start = pdf.get_y()
    pdf.set_xy(80, y_start)
    pdf.set_font("DejaVu", '', 12)
    pdf.multi_cell(0, 8, f"D·ª± ƒëo√°n: {pred_class} ({confidence*100:.2f}%)\n\n" +
                     "\n".join([f"- {cls}: {prob*100:.2f}%" for cls, prob in zip(class_names, preds)]))

    pdf.ln(50)

    pdf.set_font("DejaVu", 'B', 12)
    pdf.cell(0, 10, "Bi·ªÉu ƒë·ªì x√°c su·∫•t", ln=1)

    current_y = pdf.get_y()
    pdf.image(bar_path, x=30, y=current_y, w=140) 

    pdf_output = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")
    pdf.output(pdf_output.name)
    pdf_output.seek(0)
    return pdf_output

# Giao di·ªán Streamlit
st.set_page_config(page_title="Ph√¢n lo·∫°i b√°nh", layout="wide")

st.markdown("""
    <style>
@import url('https://fonts.googleapis.com/css2?family=Quicksand:wght@400;600&display=swap');
html, body, [class*="css"] {
    font-family: 'Quicksand', sans-serif;
}
img {
    border-radius: 12px;
    box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    max-width: 100%;
    height: auto;
}
h1 {
    color: #e65100;
    font-size: 2.2rem;
    font-weight: 700;
}
h2, h3 {
    color: #3F51B5;
    margin-top: 0.5rem;
}
.stAlert {
    border-radius: 12px;
    border-left: 6px solid #FF5722;
    box-shadow: 0 3px 10px rgba(0,0,0,0.08);
    font-size: 1rem;
}
section[data-testid="stSidebar"] {
    border-radius: 0 12px 12px 0;
    background-color: #ffffff;
    box-shadow: 2px 0 8px rgba(0,0,0,0.05);
}
.block-container {
    padding-top: 1.5rem;
    padding-bottom: 2rem;
    padding-left: 1rem;
    padding-right: 1rem;
}
/* Giao di·ªán g·ªçn g√†ng h∆°n tr√™n ƒëi·ªán tho·∫°i */
    @media screen and (max-width: 600px) {
        .stAlert {
            font-size: 0.95rem;
        }
        h1 {
            font-size: 1.5rem;
        }
}
    </style>
""", unsafe_allow_html=True)

model = load_model("Xception_banh_model.keras")
class_names = ['Cheesecake', 'Donut', 'Macaron', 'Tiramisu']

descriptions = {
    "Cheesecake": "üßÄ Cheesecake l√† lo·∫°i b√°nh ng·ªçt m·ªÅm m·ªãn l√†m t·ª´ kem ph√¥ mai, th∆∞·ªùng c√≥ ƒë·∫ø l√† b√°nh quy nghi·ªÅn.",
    "Donut": "üç© Donut l√† b√°nh v√≤ng chi√™n, th∆∞·ªùng ƒë∆∞·ª£c ph·ªß socola, ƒë∆∞·ªùng ho·∫∑c topping trang tr√≠ nhi·ªÅu m√†u.",
    "Macaron": "üåà Macaron l√† b√°nh h·∫°nh nh√¢n Ph√°p, v·ªè gi√≤n tan, b√™n trong m·ªÅm m·ªãn, nhi·ªÅu m√†u s·∫Øc ƒë·∫πp m·∫Øt.",
    "Tiramisu": "‚òï Tiramisu l√† b√°nh √ù ƒë·∫∑c tr∆∞ng v·ªõi v·ªã c√† ph√™, kem mascarpone v√† l·ªõp cacao ph·ªß b√™n tr√™n."
}
recipe_assets = {
    "Cheesecake": {
        "pdf": "https://hongminh1602.github.io/cake-xception-app/recipes/chesecake_recipe.pdf",
        "video": "https://www.youtube.com/watch?v=aMBecr0SJ8I&pp=ygUkaMaw4bubbmcgZOG6q24gbMOgbSBiw6FuaCBjaGVlc2VjYWtl"
    },
    "Donut": {
        "pdf": "https://hongminh1602.github.io/cake-xception-app/recipes/donut_recipe.pdf",
        "video": "https://www.youtube.com/watch?v=zMkLRWjahOk&pp=ygUfaMaw4bubbmcgZOG6q24gbMOgbSBiw6FuaCBkb251dNIHCQneCQGHKiGM7w%3D%3D"
    },
    "Macaron": {
        "pdf": "https://hongminh1602.github.io/cake-xception-app/recipes/macaron_recipe.pdf",
        "video": "https://www.youtube.com/watch?v=MFyc72Bfqbs&pp=ygUhaMaw4bubbmcgZOG6q24gbMOgbSBiw6FuaCBtYWNhcm9u"
    },
    "Tiramisu": {
        "pdf": "https://hongminh1602.github.io/cake-xception-app/recipes/tiramisu_recipe.pdf",
        "video": "https://www.youtube.com/watch?v=vF54bj3V5Es"
    }
}
# G·ª£i √Ω ti·ªám b√°nh theo t·ª´ng lo·∫°i (d√πng d·ªØ li·ªáu gi·∫£ ƒë·ªãnh)
locations = {
    "Cheesecake": [
    {
        "name": "Reverie Dessert ( b√°n online ) ",
        "lat": 0,  
        "lon": 0,
    }
    ],
    "Donut": [
    {
        "name": "Gi·∫£n Donuts",
        "lat": 21.018940671560365,  
        "lon": 105.84002679999999,
        "map_url": "https://maps.app.goo.gl/S2khYBf9hSV4zCQv9?g_st=iz"
    },
    {
        "name": "L·ªãm Donuts Hanoi",
        "lat": 221.03075186295445, 
        "lon": 105.84661844047851,
        "map_url": "https://maps.app.goo.gl/oNHR1FLvwJ83FJST8?g_st=iz"
    }
    ],
    "Macaron": [
    {
        "name": "La Rosette Macaron",
        "lat": 20.995968424740052, 
        "lon": 105.82483821986816,
        "map_url": "https://maps.app.goo.gl/Y6bQkQJZ2jfbtXN66"
    },
    {
        "name": "Ryan's Patisserie",
        "lat": 21.011402225563693,
        "lon": 105.81893313068578,
        "map_url": "https://maps.app.goo.gl/utpgS6Hm6xM8UKrJ8?g_st=iz"
    }
    ],
    "Tiramisu": [
    {
        "name": "Kat's Bakery",
        "lat": 21.0183411,
        "lon": 105.828166,
        "map_url": "https://www.google.com/maps/dir/20.925027,105.8642597/21.0183411,105.828166/"
    },
    {
        "name": "Cake by Xuf",
        "lat": 21.010030892626265,
        "lon": 105.83136459052602,
        "map_url": "https://maps.app.goo.gl/oxBQ2XRJxgx7mMJD7?g_st=iz"
    }
    ]
}
def predict(img):
    img = img.resize((299, 299))
    img_array = image.img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)
    preds = model.predict(img_array)[0]
    pred_class = class_names[np.argmax(preds)]
    confidence = float(np.max(preds))
    return preds, pred_class, confidence

# Sidebar
with st.sidebar.expander("üìò**Th√¥ng tin nh√≥m**"):
    st.markdown("üë• **Nh√≥m:** 14")
    st.markdown("üë®‚Äçüè´ **GVHD:** Th·∫ßy V≈© Tr·ªçng Sinh")
    st.markdown("üè´ **L·ªõp:** 242IS54A01")
    st.markdown("üìö **M√¥n:** Tr√≠ tu·ªá nh√¢n t·∫°o")
    st.sidebar.markdown("---")

with st.sidebar.expander("üß† Gi·ªõi thi·ªáu model Xception"):
    st.markdown("""
    1. **Xception** l√† vi·∫øt t·∫Øt c·ªßa *Extreme Inception* ‚Äì m·ªôt m√¥ h√¨nh m·∫°ng n∆°-ron t√≠ch ch·∫≠p (CNN) n√¢ng c·∫•p t·ª´ Inception.
    2. Thay v√¨ d√πng c√°c kh·ªëi t√≠ch ch·∫≠p ti√™u chu·∫©n, Xception s·ª≠ d·ª•ng **Depthwise Separable Convolution** ƒë·ªÉ tƒÉng hi·ªáu qu·∫£ t√≠nh to√°n.
    3. M√¥ h√¨nh n√†y c√≥ **hi·ªáu su·∫•t cao** trong ph√¢n lo·∫°i ·∫£nh, ƒë·∫∑c bi·ªát t·ªët khi √°p d·ª•ng cho c√°c t·∫≠p d·ªØ li·ªáu h√¨nh ·∫£nh c√≥ chi ti·∫øt ƒë·∫∑c tr∆∞ng nh∆∞ b√°nh ng·ªçt.
    4. Nh√≥m ƒë√£ fine-tune Xception ƒë·ªÉ ph√¢n bi·ªát gi·ªØa 4 lo·∫°i b√°nh: *Cheesecake, Donut, Macaron, Tiramisu*.
    """)

with st.sidebar.expander("üìä Model ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o"):
    st.markdown("""
    ### üîç C√°ch ho·∫°t ƒë·ªông c·ªßa m√¥ h√¨nh:
    1. üñº T·∫£i ·∫£nh b√°nh l√™n ·ª©ng d·ª•ng.
    2. üìè ·∫¢nh ƒë∆∞·ª£c resize v·ªÅ **299x299** pixel v√† chu·∫©n h√≥a d·ªØ li·ªáu.
    3. ü§ñ M√¥ h√¨nh Xception (Deep Learning) x·ª≠ l√Ω ·∫£nh ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng.
    4. üìà M√¥ h√¨nh t√≠nh to√°n x√°c su·∫•t thu·ªôc v·ªÅ t·ª´ng lo·∫°i b√°nh.
    5. ‚úÖ K·∫øt qu·∫£ cu·ªëi c√πng l√† lo·∫°i b√°nh c√≥ x√°c su·∫•t cao nh·∫•t.
    """)

st.title("üéÇ Ph√¢n lo·∫°i b√°nh v·ªõi m√¥ h√¨nh Xception")

uploaded_file = st.file_uploader("üì∑ T·∫£i ·∫£nh b√°nh l√™n", type=["jpg", "jpeg", "png"])

if uploaded_file:
    img = Image.open(uploaded_file)

    img_col, result_col = st.columns([1, 1])
    with img_col:
        st.image(img, caption="üì∏ ·∫¢nh b·∫°n v·ª´a t·∫£i", use_container_width=True)

    preds, pred_class, confidence = predict(img)

    with result_col:
        st.markdown("### üîç K·∫øt qu·∫£ d·ª± ƒëo√°n:")
        st.markdown(f"üëâ **{pred_class}** v·ªõi ƒë·ªô tin c·∫≠y **{confidence*100:.2f}%**")
        st.info(descriptions[pred_class])

    # ‚úÖ V·∫º BI·ªÇU ƒê·ªí CH·ªà N·∫æU ƒê√É T·∫¢I ·∫¢NH
    st.markdown("### üìä Bi·ªÉu ƒë·ªì x√°c su·∫•t")

    col_left, col_chart, col_right = st.columns([0.3, 6, 0.3])
    with col_chart:
        fig1, ax1 = plt.subplots(figsize=(6.5, 3.5))
        y_pos = np.arange(len(class_names))
        ax1.barh(y_pos, preds, align='center', color=["#FFC107", "#FF5722", "#9C27B0", "#3F51B5"])
        ax1.set_yticks(y_pos)
        ax1.set_yticklabels(class_names, fontsize=11)
        ax1.invert_yaxis()
        ax1.set_xlabel('X√°c su·∫•t', fontsize=11)
        ax1.set_xlim(0, 1.0)
        ax1.set_title('Ph√¢n b·ªë x√°c su·∫•t c√°c lo·∫°i b√°nh', fontsize=13)

        for i, v in enumerate(preds):
            ax1.text(v + 0.01, i, f"{v*100:.2f}%", va='center', fontsize=10)

        st.pyplot(fig1)

    # ‚úÖ T·∫†O FILE PDF CH·ªà N·∫æU ƒê√É C√ì K·∫æT QU·∫¢
    pdf_filename = st.text_input("üìÑ ƒê·∫∑t t√™n file PDF (kh√¥ng c·∫ßn .pdf)", value="bao_cao_du_doan_banh")
    if st.button("üìÑ L∆∞u k·∫øt qu·∫£ d·∫°ng PDF"):
        pdf_file = create_pdf(img, pred_class, confidence, preds, class_names, fig1)
        with open(pdf_file.name, "rb") as f:
            st.download_button(
                label="üì• T·∫£i file PDF",
                data=f,
                file_name=f"{pdf_filename}.pdf",
                mime="application/pdf"
            )

    # ‚úÖ ƒê·ªãa ch·ªâ mua 
    if pred_class in locations:
        st.markdown("### üìç G·ª£i √Ω ƒë·ªãa ƒëi·ªÉm mua b√°nh")
    
        df_map = pd.DataFrame([{
            "latitude": loc["lat"],
            "longitude": loc["lon"]
        } for loc in locations[pred_class]])
        st.map(df_map)
    
        # V·ªã tr√≠ ng∆∞·ªùi d√πng (gi·∫£ ƒë·ªãnh)
        user_lat, user_lon = 21.00892346213516, 105.82871755204096

        for item in locations[pred_class]:
            distance_km = haversine(user_lat, user_lon, item['lat'], item['lon'])
            st.markdown(f"**üç∞ {item['name']}** ‚Äì üìç C√°ch b·∫°n kho·∫£ng **{distance_km:.2f} km**")
            
            if 'map_url' in item:
                st.markdown(f"[üó∫Ô∏è Xem ƒë∆∞·ªùng ƒëi tr√™n Google Maps]({item['map_url']})", unsafe_allow_html=True)
    
    # ‚úÖ Xem c√¥ng th·ª©c v√† video h∆∞·ªõng d·∫´n 
    with st.expander("üìñ Xem c√¥ng th·ª©c v√† h∆∞·ªõng d·∫´n chi ti·∫øt"):
        st.markdown("#### üé• Video h∆∞·ªõng d·∫´n:")
        st.markdown(
            f'<a href="{recipe_assets[pred_class]["video"]}" target="_blank">üëâ Xem video h∆∞·ªõng d·∫´n </a>',
            unsafe_allow_html=True
        )
        
        st.markdown("#### üìÑ C√¥ng th·ª©c chi ti·∫øt (PDF):")
        st.markdown(
            f'<a href="{recipe_assets[pred_class]["pdf"]}" target="_blank">üëâ M·ªü c√¥ng th·ª©c d·∫°ng PDF</a>',
            unsafe_allow_html=True
        )
